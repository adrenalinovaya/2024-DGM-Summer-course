{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyfGcNY4pcXd"
   },
   "source": [
    "# Homework2: VAE and GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvqXOhwQf0c2"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07321QwCf0c3"
   },
   "source": [
    "### Problem 1: IWAE theory (1.5pt)\n",
    "\n",
    "Variational inference is based on the ELBO objective:\n",
    "$$\n",
    "    \\mathcal{L} (\\boldsymbol{\\phi}, \\boldsymbol{\\theta})  = \\mathbb{E}_{\\mathbf{z} \\sim q(\\mathbf{z} | \\mathbf{x})} \\log \\left( \\frac{p(\\mathbf{x}, \\mathbf{z} | \\boldsymbol{\\theta})}{q(\\mathbf{z}| \\mathbf{x}, \\boldsymbol{\\phi})} \\right) \\rightarrow \\max_{\\boldsymbol{\\phi}, \\boldsymbol{\\theta}}.\n",
    "$$\n",
    "ELBO is a lower bound of the log-likelihood. However if the gap between ELBO and log-likelihood is large, then our model is not optimal. In this task we discuss the way, how to improve the lower bound.\n",
    "\n",
    "The improvement was introduced in the [IWAE](https://arxiv.org/abs/1509.00519) model. This model introduces the improved version of the variational lower bound (ELBO):\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}_K (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\mathbb{E}_{\\mathbf{z}_1, \\dots, \\mathbf{z}_K \\sim q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log \\left( \\frac{1}{K}\\sum_{k=1}^K\\frac{p(\\mathbf{x}, \\mathbf{z}_k | \\boldsymbol{\\theta})}{q(\\mathbf{z}_k| \\mathbf{x}, \\boldsymbol{\\phi})} \\right) \\rightarrow \\max_{\\boldsymbol{\\phi}, \\boldsymbol{\\theta}}.\n",
    "$$\n",
    "\n",
    "Note, that the difference with the original ELBO is the sum over $K$ different latent vectors $\\mathbf{z}_k$.\n",
    "\n",
    "Moreover we can rewrite ELBO in the following form:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L} (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\frac{1}{K} \\sum_{k=1}^K\\mathcal{L} (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\frac{1}{K} \\sum_{k=1}^K \\mathbb{E}_{\\mathbf{z}_k \\sim q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log \\left( \\frac{p(\\mathbf{x}, \\mathbf{z}_k | \\boldsymbol{\\theta})}{q(\\mathbf{z}_k| \\mathbf{x}, \\boldsymbol{\\phi})} \\right) = \\frac{1}{K}  \\mathbb{E}_{\\mathbf{z}_k \\sim q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\sum_{k=1}^K \\log \\left( \\frac{p(\\mathbf{x}, \\mathbf{z}_k | \\boldsymbol{\\theta})}{q(\\mathbf{z}_k| \\mathbf{x}, \\boldsymbol{\\phi})} \\right).\n",
    "$$\n",
    "Here we see that the only difference between these two objectives ($\\mathcal{L} (\\boldsymbol{\\phi}, \\boldsymbol{\\theta})$ and $\\mathcal{L}_K (\\boldsymbol{\\phi}, \\boldsymbol{\\theta})$) is the order of sum and logarithm.\n",
    "\n",
    "Our task here is two proof that the objective $\\mathcal{L}_K (\\boldsymbol{\\phi}, \\boldsymbol{\\theta})$ is also a lower bound of log-likelihood and this lower bound is better than the initial ELBO.\n",
    "\n",
    "We have to prove the following facts:\n",
    "\n",
    "1. $\\log p(\\mathbf{x} | \\boldsymbol{\\theta}) \\geq \\mathcal{L}_K (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) \\geq \\mathcal{L}_M (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}), \\quad \\text{for } K \\geq M$;\n",
    "2.  $\\log p(\\mathbf{x} | \\boldsymbol{\\theta}) = \\lim_{K \\rightarrow \\infty} \\mathcal{L}_K (\\boldsymbol{\\phi}, \\boldsymbol{\\theta})$ if $\\frac{p(\\mathbf{x}, \\mathbf{z} | \\boldsymbol{\\theta})}{q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})}$ is bounded.\n",
    "\n",
    "**Hints:**\n",
    "1. First part of the theorem.\n",
    "\n",
    "    (a) Use the following equation inside the logarithm of $\\mathcal{L}_K (q, \\boldsymbol{\\theta})$\n",
    "$$\n",
    "    \\frac{a_1 + \\dots + a_K}{K} = \\mathbb{E}_{k_1, \\dots, k_M} \\frac{a_{k_1} + \\dots + a_{k_M}}{M}, \\quad k_1, \\dots, k_M \\sim U[1, K]\n",
    "$$\n",
    "    (b) Apply Jensen' inequality.\n",
    "3. Second part of the theorem: use the Law of large numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J37lldMf0c3"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG_UGutcCOd4"
   },
   "source": [
    "### Problem 2: Conjugate functions / f-GAN (1pt)\n",
    "\n",
    "We have discussed the framework for f-divergence minimization at the Lecture 8. There we have got the variational inequality for f-divergence using Fenchel conjugate function:\n",
    "$$\n",
    "    D_f(\\pi || p) \\geq \\sup_{T \\in \\mathcal{T}} \\left[\\mathbb{E}_{\\pi}T(\\mathbf{x}) -  \\mathbb{E}_p f^*(T(\\mathbf{x})) \\right].\n",
    "$$\n",
    "Here\n",
    "$$\n",
    "\tf^*(t) = \\sup_{u \\in \\text{dom}_f} \\left( ut - f(u) \\right), \\quad f(u) = \\sup_{t \\in \\text{dom}_{f^*}} \\left( ut - f^*(t) \\right).\n",
    "$$\n",
    "\n",
    "In this task you have to derive standard GAN objective from the variational inequality.\n",
    "\n",
    "Let define function $f(u) = u \\log u - (u + 1) \\log (u + 1)$.\n",
    "\n",
    "- Find $\\text{dom}(f)$.\n",
    "- Show that $f^*(t) = - \\log (1 - e^t)$.\n",
    "- Use reparametrization $T(\\mathbf{x}) = \\log D(\\mathbf{x})$ to get the standard GAN objective (note that $D(\\mathbf{x}) \\in (0, 1)$, explain why this reparametrization is correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pku2eJpUCQ30"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Lj4J6dDCU3a"
   },
   "source": [
    "### Problem 3: Frechet Inception Distance  (2pt)\n",
    "Let prove the theorem from the Lecture 9.\n",
    "Remember the Wasserstein metric:\n",
    "$$\n",
    "    W_s(\\pi, p) = \\inf_{\\gamma \\in \\Gamma(\\pi, p)} \\left(\\mathbb{E}_{(\\mathbf{x}, \\mathbf{y}) \\sim \\gamma} \\| \\mathbf{x} - \\mathbf{y} \\|^s\\right)^{1/s}\n",
    "$$\n",
    "\n",
    "Consider the case $\\mathbf{x} \\sim \\pi(\\mathbf{x}) = \\mathcal{N}(\\boldsymbol{\\mu}_1, \\sigma_1^2 \\mathbf{I})$, $\\mathbf{y} \\sim p(\\mathbf{y}) = \\mathcal{N}(\\boldsymbol{\\mu}_2, \\sigma_2^2 \\mathbf{I})$.\n",
    "\n",
    "Let prove that in this case\n",
    "$$\n",
    "    W_2^2(\\pi, p) = \\inf_{\\gamma \\in \\Gamma(\\pi, p)} \\mathbb{E}_{(\\mathbf{x}, \\mathbf{y}) \\sim \\gamma} \\| \\mathbf{x} - \\mathbf{y} \\|^2 = \\| \\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2 \\|^2 + m \\cdot (\\sigma_1 - \\sigma_2)^2.\n",
    "$$\n",
    "Here $m$ is a dimensionality of the space ($\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^m$).\n",
    "\n",
    "**Hints:** (one of the possible solutions)\n",
    "1. Consider the case $\\boldsymbol{\\mu}_1 = \\boldsymbol{\\mu}_2 = 0$.\n",
    "2. Use Cauchyâ€“Schwarz inequality to prove that the value given above is a minimal.\n",
    "2. Find the analytical mapping between $\\mathbf{x}$ and $\\mathbf{y}$ that gives this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0XrJ33-CXaK"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9leRbWNBqZM2",
    "outputId": "c2c328ff-500c-43c0-96ee-f2ccfd8e18b8"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "COMMIT_HASH = \"b4df45506b5dc4cd055cb00facebc504fd57571a\"\n",
    "!if [ -d dgm_utils ]; then rm -Rf dgm_utils; fi\n",
    "!git clone https://github.com/r-isachenko/dgm_utils.git\n",
    "%cd dgm_utils\n",
    "!git checkout {COMMIT_HASH}\n",
    "!pip install ./\n",
    "%cd ./..\n",
    "!rm -Rf dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nc5RAWFOqekr"
   },
   "outputs": [],
   "source": [
    "import dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIBqEphlrEGd",
    "outputId": "bf73ccc1-3e15-4d3b-ce12-267b6d71fd12"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from typing import Optional\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN3th9zXANgx"
   },
   "source": [
    "## Task 2: ResNetVAE on CIFAR10 data (4pt)\n",
    "\n",
    "In this task you will implement VAE model for CIFAR10 dataset.\n",
    "\n",
    "Let download and visualize samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "POBb7efUAQhp",
    "outputId": "09fe347d-4543-4531-987d-cd78c86a7d36"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = dgm_utils.load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "dgm_utils.visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biYy9_rWd-DY"
   },
   "source": [
    "Now it is time to define our model. Our model will have the following structure:\n",
    "\n",
    "* Prior distribution is standard Normal ($p(\\mathbf{z}) = \\mathcal{N}(0, I)$).\n",
    "* Variational posterior distribution (or encoder) is $q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))$. Here $\\boldsymbol{\\phi}$ denotes all parameters of the encoder neural network. We will assume that covariance matrice $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x})$ is diagonal.\n",
    "* Generative distribution (or decoder) is $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))$. Here $\\boldsymbol{\\theta}$ denotes all parameters of the decoder neural network. Please note, that here we will use continuous distribution for our variables $\\mathbf{x}$.\n",
    "* We do not fit the covariance matrix $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ in the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$. We assume that it is identical ($\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\mathbf{I}$). We will use the $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ (mean of the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$) as model samples.\n",
    "* Our encoder and decoder will be convolutional neural networks.\n",
    "* Model objective is slightly modified ELBO:\n",
    "$$\n",
    "    \\mathcal{L}(\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\mathbb{E}_{q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) - \\beta * KL (q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) || p(\\mathbf{z})).\n",
    "$$\n",
    "Here we introduce the parameter $\\beta$. It reweights KL term in the total loss. It a standard heuristics that allows to get more accurate model. In this exercise you have to play with it, starting with the value $\\beta = 1$ (standard ELBO).\n",
    "\n",
    "To make the expectation is independent of parameters $\\boldsymbol{\\phi}$, we will use reparametrization trick.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxqxyXZBbKfy"
   },
   "source": [
    "To calculate the loss, we should derive\n",
    "- $\\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$, note that generative distribution is $\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))$.\n",
    "- KL between $q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))$ and $\\mathcal{N}(0, \\mathbf{I})$.\n",
    "\n",
    "Let start with the helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZEUyHuxE39I"
   },
   "outputs": [],
   "source": [
    "def get_normal_KL(\n",
    "    mean_1: torch.Tensor,\n",
    "    log_std_1: torch.Tensor,\n",
    "    mean_2: Optional[torch.Tensor] = None,\n",
    "    log_std_2: Optional[torch.Tensor] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :Parameters:\n",
    "    mean_1: means of normal distributions (1)\n",
    "    log_std_1 : standard deviations of normal distributions (1)\n",
    "    mean_2: means of normal distributions (2)\n",
    "    log_std_2 : standard deviations of normal distributions (2)\n",
    "    :Outputs:\n",
    "    kl divergence of the normal distributions (1) and normal distributions (2)\n",
    "    ---\n",
    "    This function should return the value of KL(p1 || p2),\n",
    "    where p1 = Normal(mean_1, exp(log_std_1) ** 2), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n",
    "    If mean_2 and log_std_2 are None values, we will use standard normal distribution.\n",
    "    Note that we consider the case of diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "    if mean_2 is None:\n",
    "        mean_2 = torch.zeros_like(mean_1)\n",
    "    if log_std_2 is None:\n",
    "        log_std_2 = torch.zeros_like(log_std_1)\n",
    "    assert mean_1.shape == log_std_1.shape == mean_2.shape == log_std_2.shape\n",
    "    # ====\n",
    "    # your code\n",
    "     \n",
    "    # ====\n",
    "\n",
    "\n",
    "def test_KL():\n",
    "    assert np.isclose(\n",
    "        get_normal_KL(\n",
    "            torch.tensor(2), torch.tensor(3), torch.tensor(0), torch.tensor(0)\n",
    "        ).numpy(),\n",
    "        200.2144,\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "    assert np.isclose(\n",
    "        get_normal_KL(\n",
    "            torch.tensor(2), torch.tensor(3), torch.tensor(4), torch.tensor(5)\n",
    "        ).numpy(),\n",
    "        1.50925,\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "    assert np.allclose(\n",
    "        get_normal_KL(\n",
    "            torch.tensor((10, 10)), torch.tensor((2, 4)), torch.tensor((3, 5))\n",
    "        ).numpy(),\n",
    "        [49.2990, 1498.479],\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "test_KL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "871Pfpm1TiWF"
   },
   "outputs": [],
   "source": [
    "def get_normal_nll(\n",
    "    x: torch.Tensor, mean: torch.Tensor, log_std: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function should return the negative log likelihood log p(x),\n",
    "    where p(x) = Normal(x | mean, exp(log_std) ** 2).\n",
    "    Note that we consider the case of diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "    # ====\n",
    "    # your code\n",
    "\n",
    "    # ====\n",
    "\n",
    "\n",
    "def test_NLL():\n",
    "    assert np.isclose(\n",
    "        get_normal_nll(torch.tensor(2), torch.tensor(2), torch.tensor(3)).numpy(),\n",
    "        3.9189,\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "    assert np.isclose(\n",
    "        get_normal_nll(torch.tensor(5), torch.tensor(-3), torch.tensor(6)).numpy(),\n",
    "        6.9191,\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "    assert np.allclose(\n",
    "        get_normal_nll(\n",
    "            torch.tensor((10, 10)), torch.tensor((2, 4)), torch.tensor((3, 5))\n",
    "        ).numpy(),\n",
    "        np.array([3.9982, 5.9197]),\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "\n",
    "\n",
    "test_NLL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ7cIAhkfhif"
   },
   "source": [
    "Let define our encoder and decoder neural networks. We will use ResNet-like encoder and decoder.\n",
    "\n",
    "First of all let define basic ResNet block. It will be the basic block for our encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBZA5vBwf0c-"
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, final_relu=True):\n",
    "        super().__init__()\n",
    "        self.final_relu = final_relu\n",
    "        # ====\n",
    "        # your code\n",
    "        # here you could try different network structures\n",
    "        # we suggest to use the following:\n",
    "        # residual(x) = conv(bn(relu(conv(bn(x)))))\n",
    "        # output = relu(conv1x1(input) + residual(input))\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        \n",
    "        # ====\n",
    "        if self.final_relu:\n",
    "            result = self.relu2(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "def test_resnet_block():\n",
    "    test_inp = torch.randn(5, 64, 128, 128)\n",
    "\n",
    "    for out_channels in [64, 128]:\n",
    "        for kernel_size in [3, 5, 7]:\n",
    "            for stride in [1, 2, 4]:\n",
    "                resnet_block = ResNetBlock(in_channels=64, out_channels=out_channels,\n",
    "                                        kernel_size=kernel_size, stride=stride)\n",
    "                assert list(resnet_block(test_inp).shape) == [5, out_channels, 128 // stride, 128 // stride]\n",
    "\n",
    "\n",
    "test_resnet_block()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5njl8CQpvqw"
   },
   "source": [
    "Now let define basic ResNet block. It will be the basic block for our decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19M3VevKYCrn"
   },
   "outputs": [],
   "source": [
    "class ResNetTransposeBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, final_relu=True):\n",
    "        super().__init__()\n",
    "        self.final_relu = final_relu\n",
    "        # ====\n",
    "        # your code\n",
    "        # here you could try different network structures\n",
    "        # we suggest to use the following:\n",
    "        # output = conv(bn(f(input))) + f(input), where:\n",
    "        # f(x) = upconv(bn(x))\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "\n",
    "        # ====\n",
    "        if self.final_relu:\n",
    "            result = self.relu1(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "def test_resnet_transposed_block():\n",
    "    test_inp = torch.randn(5, 64, 64, 64)\n",
    "    for out_channels in [64, 128]:\n",
    "        for kernel_size in [4, 6, 8]:\n",
    "            for stride in [2, 4]:\n",
    "                resnet_block = ResNetTransposeBlock(\n",
    "                    in_channels=64, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "                assert list(resnet_block(test_inp).shape) == [5, out_channels, 64 * stride, 64 * stride]\n",
    "\n",
    "\n",
    "test_resnet_transposed_block()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAYKzNCqp2o-"
   },
   "source": [
    "Now we are to define our encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFkDOrg7YVrB"
   },
   "outputs": [],
   "source": [
    "class ConvResNetEncoder(nn.Module):\n",
    "    def __init__(self, input_shape, n_latent):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.n_latent = n_latent\n",
    "        # ====\n",
    "        # your code\n",
    "        # our suggestions:\n",
    "        # - try to combine multiple resnet blocks\n",
    "        # - place Flatten + Linear at the end\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all blocks defined in init\n",
    "        # split output tensor to mu and log_std\n",
    "        \n",
    "        mu, log_std = \n",
    "        # ====\n",
    "        return mu, log_std\n",
    "\n",
    "\n",
    "class ConvResNetDecoder(nn.Module):\n",
    "    def __init__(self, n_latent, output_shape):\n",
    "        super().__init__()\n",
    "        self.n_latent = n_latent\n",
    "        self.output_shape = output_shape\n",
    "        # ====\n",
    "        # your code\n",
    "        # our suggestions:\n",
    "        # - apply linear layer to the input\n",
    "        # - reshape output matrix to 4-dims tensor\n",
    "        # - try to combine multiple resnet transposed blocks\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, z):\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all blocks defined in init\n",
    "\n",
    "        # ====\n",
    "        return out\n",
    "\n",
    "\n",
    "def test_convresnet_models():\n",
    "    test_enc = ConvResNetEncoder((3, 32, 32), n_latent=10)\n",
    "    inp = torch.randn((4, 3, 32, 32))\n",
    "    mu, std = test_enc(inp)\n",
    "\n",
    "    assert list(mu.shape) == [4, 10]\n",
    "    assert list(std.shape) == [4, 10]\n",
    "\n",
    "    test_dec = ConvResNetDecoder(10, (3, 32, 32))\n",
    "    inp = torch.randn(4, 10)\n",
    "    assert list(test_dec(inp).shape) == [4, 3, 32, 32]\n",
    "\n",
    "\n",
    "test_convresnet_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXtOjEvbftM9"
   },
   "source": [
    "We are ready to implement VAE model for image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3T4RRzUfrdg"
   },
   "outputs": [],
   "source": [
    "class ConvResNetVAE(nn.Module):\n",
    "    def __init__(self, input_shape: tuple, n_latent: int, beta: float = 1) -> None:\n",
    "        super().__init__()\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.n_latent = n_latent\n",
    "        self.beta = beta\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        self.encoder = \n",
    "        self.decoder = \n",
    "        # ====\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def prior(self, n: int) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # return n samples from prior distribution (we use standart normal for prior)\n",
    "        z = \n",
    "        # ====\n",
    "\n",
    "        z = z.to(self.device)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply encoder to get mu_z, log_std_z\n",
    "        # 2) apply reparametrization trick (use self.prior)\n",
    "        # 3) apply decoder to get mu_x (which corresponds to reconstructed x)\n",
    "        mu_z, log_std_z = \n",
    "        x_recon = \n",
    "        # ====\n",
    "        return mu_z, log_std_z, x_recon\n",
    "\n",
    "    def loss(self, x: torch.Tensor) -> dict:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) make forward step to get mu_z, log_std_z, x_recon\n",
    "        # 2) calculate recon_loss (use get_normal_nll)\n",
    "        # 3) calcucalte kl_loss (use get_normal_KL)\n",
    "\n",
    "        recon_loss = \n",
    "        kl_loss = \n",
    "        # ====\n",
    "        return {\n",
    "            \"elbo_loss\": recon_loss + self.beta * kl_loss,\n",
    "            \"recon_loss\": recon_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def sample(self, n: int) -> np.ndarray:\n",
    "        with torch.no_grad():\n",
    "            # ====\n",
    "            # your code\n",
    "            # 1) generate prior samples\n",
    "            # 2) apply decoder\n",
    "            x_recon = \n",
    "            # ====\n",
    "            samples = torch.clamp(x_recon, -1, 1)\n",
    "        return samples * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxeq_hyUqzuk"
   },
   "source": [
    "That is all! We are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "id": "vr9PNknYaLTx",
    "outputId": "ef648afa-173b-444e-d422-798a3b01388e"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "\n",
    "BATCH_SIZE = \n",
    "EPOCHS = \n",
    "LR = \n",
    "N_LATENS = \n",
    "BETA = \n",
    "# ====\n",
    "\n",
    "# we center the data, because it helps the model to fit\n",
    "centered_train_data = train_data * 2 - 1\n",
    "centered_test_data = test_data * 2 - 1\n",
    "\n",
    "train_loader = data.DataLoader(centered_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(centered_test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = ConvResNetVAE((3, 32, 32), N_LATENS, BETA)\n",
    "\n",
    "# ====\n",
    "# your code\n",
    "# choose any optimizer/scheduler as you want\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# ====\n",
    "\n",
    "dgm_utils.train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    loss_key=\"elbo_loss\",\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlE8JlD-f1B9"
   },
   "source": [
    "Now we could visualize the model outputs.\n",
    "\n",
    "1. We could sample new images from our model (sample latent variable from the prior and apply the decoder).\n",
    "2. We could visualize image reconstructions (apply the encoder and the decoder to the fixed image).\n",
    "3. Visualize interpolations (apply the encoder to two images $\\mathbf{x}_1$ and $\\mathbf{x}_2$ to obtain the latent variables $\\mathbf{z}_1$ and $\\mathbf{z}_2$, apply the decoder to the latent variables $\\mathbf{z}$ lying on the segment between $\\mathbf{z}_1$ and $\\mathbf{z}_2$).\n",
    "\n",
    "**Note:** it is ok that your samples are blurry. We do not use difficult architectures and do not tune hyperparameters carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYQWcZ02aq9X"
   },
   "outputs": [],
   "source": [
    "samples = model.sample(100).cpu().numpy()\n",
    "\n",
    "x = next(iter(test_loader))[:50]\n",
    "\n",
    "x = x.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z, _ = model.encoder(x)\n",
    "    x_recon = torch.clamp(model.decoder(z), -1, 1)\n",
    "reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32) * 0.5 + 0.5\n",
    "reconstructions = reconstructions.cpu().numpy()\n",
    "\n",
    "x = next(iter(test_loader))[:20]\n",
    "x = x.to(model.device)\n",
    "with torch.no_grad():\n",
    "    z, _ = model.encoder(x)\n",
    "    z1, z2 = z.chunk(2, dim=0)\n",
    "    interps = [model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in np.linspace(0, 1, 10)]\n",
    "    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n",
    "    interps = torch.clamp(interps, -1, 1) * 0.5 + 0.5\n",
    "interps = interps.cpu().numpy()\n",
    "\n",
    "dgm_utils.show_samples(reconstructions, 'CIFAR10 reconstructions')\n",
    "dgm_utils.show_samples(samples, 'CIFAR10 samples')\n",
    "dgm_utils.show_samples(interps, 'CIFAR10 interpolation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPoIEPC6Dm9I"
   },
   "source": [
    "## Task 3: Wasserstein GANs for CIFAR 10 (5pt)\n",
    "\n",
    "In this task you will fit different kinds of Wasserstein GANs (different ways to enforce Lipschitzness) that we discussed at the Lecture 8 to the CIFAR10 dataset\n",
    "* [WGAN](https://arxiv.org/abs/1701.07875) - standard Wasserstein GAN with weight clipping;\n",
    "* [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf) - Wasserstein GAN with Gradient Penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0HFoym7Do2e"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = dgm_utils.load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "dgm_utils.visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVzzpUlKDuLQ"
   },
   "source": [
    "### Problem 1: WGAN (3pt)\n",
    "\n",
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness of the critic.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "\\min_{G} W(\\pi || p) \\approx \\min_{G} \\max_{\\boldsymbol{\\phi} \\in \\boldsymbol{\\Phi}} \\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} f_{\\boldsymbol{\\phi}}(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{z})} f_{\\boldsymbol{\\phi}}(G_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\right].\n",
    "$$\n",
    "Here $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$ is the critic model. The critic weights $\\boldsymbol{\\phi}$ should lie in the compact set $\\boldsymbol{\\Phi} = [-c, c]^d$.\n",
    "\n",
    "In this task we will use convolutional networks for the generator $G_{\\boldsymbol{\\theta}}(\\mathbf{z})$ and the critic $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$.\n",
    "\n",
    "First of all, let define generator network. It will be the same for all WGAN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0GIJTFlCDuk7"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size: int = 128, n_channels: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.input_size = input_size\n",
    "        # ====\n",
    "        # your code\n",
    "\n",
    "        # ====\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all layers\n",
    "        output = \n",
    "        # ====\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "    def sample(self, n_samples: int) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "        output = \n",
    "        # ====\n",
    "        return output\n",
    "\n",
    "\n",
    "def test_conv_generator():\n",
    "    model = ConvGenerator(input_size=4, n_channels=32)\n",
    "    x = torch.randn((2, 4))\n",
    "    out = model(x)\n",
    "    assert list(out.size()) == [2, 3, 32, 32], out.size()\n",
    "\n",
    "    out = model.sample(10)\n",
    "    assert list(out.size()) == [10, 3, 32, 32], out.size()\n",
    "\n",
    "\n",
    "test_conv_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPjWNnyDD55O"
   },
   "source": [
    "Now it is time to define our critic. Here we will use the same class for all WGAN models, but the arguments will depend on the WGAN mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "olKNtlAjD7VU"
   },
   "outputs": [],
   "source": [
    "class ConvCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_channels: int, clip_c: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.clip_c = clip_c\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def clip_weights(self) -> None:\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "                # ====\n",
    "                # your code\n",
    "                # clip the weight to the range [-clip_c, clip_c]\n",
    "                weight = torch.clamp(layer.weight, -self.clip_c, self.clip_c)\n",
    "                # ====\n",
    "                layer.weight.data = weight\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) clip the critic weights (if clip_c is given)\n",
    "        # 2) apply all layers\n",
    "        output = \n",
    "        # ====\n",
    "        return output\n",
    "\n",
    "\n",
    "def test_conv_critic():\n",
    "    model = ConvCritic(n_channels=4, clip_c=0.01)\n",
    "    x = torch.randn((2, 3, 32, 32))\n",
    "    out = model(x)\n",
    "    assert list(out.size()) == [2, 1], out.size()\n",
    "\n",
    "\n",
    "test_conv_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cySY8x7cD8wL"
   },
   "outputs": [],
   "source": [
    "def train_wgan(\n",
    "    generator: nn.Module,\n",
    "    critic: nn.Module,\n",
    "    train_loader: object,\n",
    "    critic_steps: int,\n",
    "    batch_size: int,\n",
    "    n_epochs: int,\n",
    "    lr: float,\n",
    "    device: str = \"cuda\",\n",
    "    gp_weight: Optional[float] = None,\n",
    ") -> dict:\n",
    "\n",
    "    critic = critic.to(device)\n",
    "    generator = generator.to(device)\n",
    "    critic.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    batch_loss_history = {\"discriminator_losses\": [], \"generator_losses\": []}\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        critic.train()\n",
    "        generator.train()\n",
    "        for batch_i, x in enumerate(train_loader):\n",
    "            curr_iter += 1\n",
    "            x = x.to(device)\n",
    "\n",
    "            # do a critic update\n",
    "            critic_optimizer.zero_grad()\n",
    "            fake_data = generator.sample(x.shape[0])\n",
    "\n",
    "            # ====\n",
    "            # your code\n",
    "            # D(x_fake) - D(x_real)\n",
    "            d_loss = \n",
    "            # ====\n",
    "\n",
    "            if gp_weight is not None:\n",
    "                gp = gradient_penalty(critic, x, fake_data)\n",
    "                d_loss += gp_weight * gp\n",
    "\n",
    "            d_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # generator update\n",
    "            if curr_iter % critic_steps == 0:\n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_data = generator.sample(batch_size)\n",
    "                # ====\n",
    "                # your code\n",
    "                # -D(x_fake)\n",
    "                g_loss = \n",
    "                # ====\n",
    "                g_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "\n",
    "                batch_loss_history[\"generator_losses\"].append(g_loss.data.cpu().numpy())\n",
    "                batch_loss_history[\"discriminator_losses\"].append(\n",
    "                    d_loss.data.cpu().numpy()\n",
    "                )\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        generator.eval()\n",
    "        critic.eval()\n",
    "        with torch.no_grad():\n",
    "            samples = generator.sample(100)\n",
    "            samples = samples.cpu().detach().numpy()\n",
    "\n",
    "        dgm_utils.show_samples(samples, title=f\"Generated samples: epoch: {epoch_i}\")\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glSbdXh2SUk9"
   },
   "outputs": [],
   "source": [
    "# do not change this function\n",
    "def plot_losses(losses: np.ndarray, title: str):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Iterations\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kNhR8_sMD-QZ",
    "outputId": "a1f824b7-6ee3-4559-edfb-47203b355cbd"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "N_CHANNELS = \n",
    "N_EPOCHS = \n",
    "CRITIC_STEPS = \n",
    "CLIP_C = \n",
    "LR = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS, clip_c=CLIP_C)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQI0S7QJEAiy"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WL0HvUrgEBtR"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(100)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "dgm_utils.show_samples(samples, title=\"CIFAR-10 WGAN-generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "867xWtpOEDZr"
   },
   "source": [
    "### Problem 2: WGAN-GP for CIFAR 10 (2pt)\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "    W(\\pi || p) = \\underbrace{\\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{x} | \\boldsymbol{\\theta})} f(\\mathbf{x})}_{\\text{original critic loss}} + \\lambda \\underbrace{\\mathbb{E}_{U[0, 1]} \\left[ \\left( \\| \\nabla_{\\hat{\\mathbf{x}}} f(\\hat{\\mathbf{x}}) \\|_2 - 1 \\right) ^ 2\\right]}_{\\text{gradient penalty}},\n",
    "$$\n",
    "where the samples $\\hat{\\mathbf{x}}_t = t \\mathbf{x} + (1 - t) \\mathbf{y}$ with $t \\in [0, 1]$ are uniformly sampled along straight lines between pairs of points: $\\mathbf{x}$ from the data distribution $\\pi(\\mathbf{x})$ and $\\mathbf{y}$ from the generator distribution $p(\\mathbf{x} | \\boldsymbol{\\theta}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCLceTqnEFCH"
   },
   "source": [
    "Let define our gradient penalty loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2EeSZAlAEGVn"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(\n",
    "    critic: object, real_data: torch.Tensor, fake_data: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    batch_size = real_data.shape[0]\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # Calculate interpolation x_t = t * x_real + (1 - t) x_fake\n",
    "    # 1) sample t\n",
    "    # 2) create x_t (be careful about shapes)\n",
    "    # 3) apply critic to x_t\n",
    "\n",
    "    x_t = \n",
    "    d_output = \n",
    "    # ====\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_output,\n",
    "        inputs=x_t,\n",
    "        grad_outputs=torch.ones(d_output.size()).to(fake_data.device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)\n",
    "    # ====\n",
    "    # your code\n",
    "    # compute gradient norm\n",
    "    gradients_norm = \n",
    "    # ====\n",
    "    return ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def test_gradient_penalty():\n",
    "    x = np.random.normal(size=(10, 4))\n",
    "    x_norm = np.mean(np.sqrt(x**2))\n",
    "    x = torch.randn(size=(10, 4))\n",
    "    x.requires_grad = True\n",
    "    assert gradient_penalty(lambda x: x, x, x).numpy() == 1\n",
    "    assert gradient_penalty(lambda x: x * 0, x, x).numpy() == 1\n",
    "\n",
    "\n",
    "test_gradient_penalty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vJp2Y-QEH0Y"
   },
   "source": [
    "That is all :)\n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aaol9W9vEJAg"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "N_CHANNELS = \n",
    "N_EPOCHS = \n",
    "CRITIC_STEPS = \n",
    "GP_WEIGHT = \n",
    "LR = 1e-4  \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm20Ms_JELGT"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gPuv5FzHEMdk"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(100)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "dgm_utils.show_samples(samples, title=\"CIFAR-10 WGAN-GP-generated samples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
